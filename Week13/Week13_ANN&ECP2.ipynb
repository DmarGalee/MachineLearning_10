{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0SypLHdiWlA",
        "outputId": "6cba5d58-4de5-4baa-c16b-36e564942859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi pada data test: 0.9667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encoding (fixed parameter name)\n",
        "encoder = OneHotEncoder(sparse_output=False)   # ← this is the only change\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data test: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tugas 2\n",
        "\n",
        "- Ubah jumlah neuron hidden layer.\n",
        "- Bandingkan akurasi dengan konfigurasi awal."
      ],
      "metadata": {
        "id": "HuzbnJXEjYP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encoding (fixed parameter name)\n",
        "encoder = OneHotEncoder(sparse_output=False)   # ← this is the only change\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(12, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Akurasi pada data test: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb5XozZrkTZx",
        "outputId": "366b98b6-66cd-4452-beb1-d5f7888e273f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi pada data test: 0.9667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan\n",
        "- Kapasitas sudah memadai Jika model awal sudah punya kapasitas lebih dari cukup untuk memisahkan kelas, menambahkan neuron ekstra tidak meningkatkan generalisasi — hanya menambah parameter yang tidak diperlukan.\n",
        "- Overfitting vs Underfitting\n",
        "Kedua model mungkin fit dengan sangat baik ke data training tanpa overfitting berlebih sehingga akurasi test tak berubah. Atau keduanya sedikit overfit tetapi performa test tetap sama."
      ],
      "metadata": {
        "id": "b4mnFxMmk8Xg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tugas 3\n",
        "\n",
        "- Bandingkan Sigmoid vs ReLU pada dataset Iris.\n",
        "\n",
        "- Catat perbedaan loss dan akurasi."
      ],
      "metadata": {
        "id": "Rf8FQrs8lwvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encoding (fixed parameter name)\n",
        "encoder = OneHotEncoder(sparse_output=False)   # ← this is the only change\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='sigmoid', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_sig = model.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
        "\n",
        "loss_sig, acc_sig = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Sigmoid → Loss:\", loss_sig, \" Accuracy:\", acc_sig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fjPZbovlIEp",
        "outputId": "47be557c-a5af-46a9-ad0c-ae620e39d082"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid → Loss: 0.5614102482795715  Accuracy: 0.9333333373069763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hidden layer (16,12)\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encoding (fixed parameter name)\n",
        "encoder = OneHotEncoder(sparse_output=False)   # ← this is the only change\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='sigmoid', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(12, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_sig = model.fit(X_train, y_train, epochs=50, batch_size=8, verbose=0)\n",
        "\n",
        "loss_sig, acc_sig = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Sigmoid → Loss:\", loss_sig, \" Accuracy:\", acc_sig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0jzGd-AmBft",
        "outputId": "bf5bdda3-a2af-4f63-a379-84a2f5dd236c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid → Loss: 0.5548325777053833  Accuracy: 0.9666666388511658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perbandingan\n",
        "- ReLU hampir selalu unggul pada hidden layer\n",
        "- ReLU tidak mengalami vanishing gradient\n",
        "- Gradien besar → learning cepat\n",
        "- Cocok untuk dataset kecil maupun besar\n",
        "- Karena data Iris cukup mudah, ReLU menang stabil\n",
        "- Itulah sebabnya akurasi ReLU = 0.9667 (96.67%) pada dua arsitektur\n",
        "\n",
        "Sigmoid lebih lambat belajar → akurasi awal turun\n",
        "- Pada arsitektur 10–8, hasil Sigmoid:\n",
        "- 0.9333 atau 93.33%\n",
        "\n",
        "Sigmoid membaik setelah neuron diperbesar\n",
        "- Ketika neuron ditambah 16–12, akurasi Sigmoid meningkat menjadi:\n",
        "- 0.9667 atau 96.67%\n",
        "Yang berarti:\n",
        "\n",
        "- Penambahan neuron memberi lebih banyak kapasitas\n",
        "- Sigmoid butuh kapasitas lebih besar untuk belajar pola non-linear\n",
        "- Lebih banyak neuron → gradien yang “menyelamatkan” training"
      ],
      "metadata": {
        "id": "lr-Kq27TnGB0"
      }
    }
  ]
}